\section{Introduction}
\label{sec:intro}
Understanding the causal factors underlying high-dimensional unstructured data, like images or videos, is a central challenge in machine learning and scientific discovery. Causal Representation Learning (CRL) has emerged as a promising framework to tackle this problem by recovering the latent causal variables and their relations from raw observations, or pursuing meaningful abstractions of fine-grained micro-variables. In general, CRL seeks to go beyond mere correlational patterns, offering representations that reflect the true generative mechanisms of data. 

Despite rapid theoretical and methodological progress, the evaluation of CRL methods remains an open challenge. A major bottleneck lies in the absence of a real-world database with accessible ground-truth causal structures. 
This limitation forces existing evaluation strategies into a trade-off between realism and evaluative rigor. On the one hand, some methods adopt simplistic synthetic environments, such as physical process~\cite{yao2022temporally,yao2021learning,li2020causal} or 3D object generation~\cite{liu2025causal3d,zimmermann2021contrastive}, which enable precise verification but fall short in realism. For instance, ~\citet{yao2021learning} uses a physical setup where balls are connected by invisible springs to test whether CRL methods can recover object identities and their latent interactions. On the other hand, some works attempt to evaluate CRL indirectly via performance on real-world downstream tasks, such as domain adaptation/generalization~\cite{kong2022partial,salaudeen2024domain} and visual reasoning~\cite{chen2024caring}. However, these real datasets lack annotated causal variables or structures, making it difficult to rigorously assess whether a method truly recovers causal factors or merely captures task-relevant correlations.
This trade-off between realism and evaluative precision significantly hampers the ability to systematically compare and advance CRL methods.

\begin{wrapfigure}{l}{0.5\textwidth}
  \centering
  \vspace{-10pt} % adjust vertical spacing as needed
  \includegraphics[width=0.5\textwidth]{figs/benchmark_overall.pdf}
  \vspace{-5pt}
  \caption{\textbf{The CausalVerse dataset.} CausalVerse is organized with a hierarchical domain-scene-instance structure. We showcase four diverse domains: static generation, physical simulation, robotic manipulation, and traffic analysis. Within each domain, multiple scenes are designed to reflect distinct causal variables and structures. Sample instances are generated using simulation tools such as Unreal Engine 4, with each instance grounded in a predefined causal graph. }
  \label{fig:benchmark_overall}
   \vspace{-0.5cm}
\end{wrapfigure}
To address this limitation, we introduce CausalVerse, a new benchmark specifically designed for causal representation learning. CausalVerse is a high-fidelity simulated visual dataset that combines realistic visual complexity with complete access to ground-truth causal variables and structures. Specifically, we carefully designed a set of scenes with well-defined causal factors and leveraged advanced rendering engines such as Blender and Unreal Engine 4 to generate high-quality simulated images and videos. The dataset includes around 200 thousand images and 300 million video frames across 24 sub-scenes drawn from four diverse domains: static image generation, dynamic physical simulations, robotic manipulation, and traffic scene analysis. These domains cover a broad spectrum of settings, ranging from static to dynamic, single-agent to multi-agent, and simple to highly structured environments.
In addition, CausalVerse goes beyond static annotations by providing access to the entire simulation process, enabling configurable access to the underlying causal graphs, such as domain labels, temporal dependencies, and intervention histories. This flexibility allows researchers to modify the dataset to satisfy specific theoretical assumptions and experimental setups in CRL.
As summarized in Table \ref{tab:causal_benchmarks} compared to existing CRL benchmarks, CausalVerse offers greater scalability, richer diversity of task environments, high-dimensional latent spaces, and significantly improved realism, making it a more comprehensive and practical testbed for developing and evaluating causal representation methods.

Using this benchmark, we conduct a series of empirical evaluations of representative CRL methods grounded in diverse principles, providing comparative insights into their strengths, limitations, and applicability across a range of settings. Our results reveal that, despite recent theoretical advances in identifiability for CRL, applying these methods in practice remains challenging, particularly in scenarios involving complex visual content. Furthermore, we challenge existing CRL methods under unmet assumptions, offering practical guidance for researchers, especially newcomers who may not have prior knowledge of the specific assumptions underlying their data.
By releasing CausalVerse along with these empirical analyses, we aim to advance the development of more robust and generalizable CRL methods, and support both researchers and practitioners in selecting appropriate tools for addressing real-world problems from a causal perspective.

We summarize the main contributions of this paper as follows: (1) \textbf{CausalVerse Benchmark:} A large-scale, high-fidelity visual dataset for CRL, featuring realistic complexity, high-dimensional latent spaces, and full access to ground-truth causal structures. (2) \textbf{Diverse Scenarios and Configurable Settings:} Around 200k images and 300 million video frames across 24 sub-scenes in four domains, with the whole simulation process to support configurable causal settings. (3) \textbf{Empirical Evaluation:} Systematic comparison of CRL methods under varying assumptions and conditions. (4) \textbf{Practical Insights:} Guidance for selecting or designing CRL methods in real-world scenarios, especially under imperfect assumptions.