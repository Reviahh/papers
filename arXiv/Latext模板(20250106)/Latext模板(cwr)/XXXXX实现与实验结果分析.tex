\hspace*{2em}本章在深入分析了基于注意力的双视图网络模型的原理后，对该方法进行了复现，并扩展了其数据集，在VisDial v0.9上也做了训练和评估，然后将上节提到的优化器和激活函数的改进写入其中，并以消融实验验证了它们的效果，之后测试了位置编码和损失函数的实际效果，最后进行了部分结果的可视化展示。

\section{XXXXX实现}

\subsection{平台与环境配置}

由于该模型网络结构复杂，所采用的VisDial v1.0数据集规模庞大，大小约100G,所以起初在自己的1050ti上训练极为缓慢，训练了38.5小时后才训练了6个轮次，还发生显存溢出的错误，所以之后我在AutoDL的云端GPU上运行，用了两块2080tiGPU，完成一次训练大概8小时，尽管还是缓慢，但勉强可以接受。实验环境如下：GPU为RTX2080ti（11GB）*2，CPU为8核Intel(R) Xeon(R) Silver 4110 CPU @ 2.10GHz，实际Conda环境下CUDA版本为10.1，Python版本3.7。
\subsection{问题和解决方法}

\subsection{实现过程}

\section{实验数据集介绍}

\section{实验结果与分析}

\section{结果可视化展示}

\section{本章小结}
本文在深入分析了基于注意力的双视图网络模型后，完成了对该模型的改进，本章通过实验测试了它的可行性，效果和缺陷。实验表明，优化器和激活函数的改进取得了不错的效果，而模型输入编码和损失函数的改进存在局限性，体现在训练速率降低或在训练多轮次后改进效果变差或者没有明显改进上，但是在进行短期且灵活的训练和评估时效果可以接受。