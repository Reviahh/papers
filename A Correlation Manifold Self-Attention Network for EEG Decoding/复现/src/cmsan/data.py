"""
CMSAN Data Adapter (Fixed based on Scan Results)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ä¿®å¤è¯´æ˜:
1. BCIC: ä¸“é—¨å¤„ç† T (Train) å’Œ E (Eval) åˆ†ç¦»çš„æ–‡ä»¶ç»“æ„ï¼Œè‡ªåŠ¨åˆå¹¶ã€‚
2. BCIcha/MAMEM: ç¡®è®¤é”®åä¸º x_test/y_testï¼Œç›´æ¥åŠ è½½ã€‚
"""

import numpy as np
import jax.numpy as jnp
from scipy.io import loadmat
from pathlib import Path
import logging

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
if not logger.handlers:
    logging.basicConfig(level=logging.INFO)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  1. æ•°æ®é›†å…ƒæ•°æ®
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DATASET_META = {
    'bcic':   {'C': 22, 'T': 438, 'K': 4,  'folder': 'BCICIV_2a_mat'},
    'mamem':  {'C': 8,  'T': 125, 'K': 5,  'folder': 'MAMEM'},
    'bcicha': {'C': 56, 'T': 160, 'K': 2,  'folder': 'BCIcha'},
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  2. è¾…åŠ©å‡½æ•°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def normalize(X):
    """Z-Score æ ‡å‡†åŒ–"""
    mean = X.mean(axis=(1, 2), keepdims=True)
    std = X.std(axis=(1, 2), keepdims=True) + 1e-8
    return (X - mean) / std

def find_file(base_roots, filename):
    """åœ¨å¤šä¸ªç›®å½•ä¸­æœç´¢æ–‡ä»¶"""
    for root in base_roots:
        path = root / filename
        if path.exists():
            return path
    return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  3. ä¸“ç”¨åŠ è½½é€»è¾‘
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _load_bcic_merged(t_path, e_path):
    """
    BCIC ä¸“ç”¨ï¼šåˆå¹¶ T (Train) å’Œ E (Eval) æ–‡ä»¶
    """
    X_list, y_list = [], []
    
    # 1. åŠ è½½ Training Set
    if t_path and t_path.exists():
        d = loadmat(str(t_path))
        # æ‰«æç»“æœæ˜¾ç¤º T æ–‡ä»¶é‡Œæ˜¯ x_train
        if 'x_train' in d:
            X_list.append(d['x_train'])
            y_list.append(d['y_train'])
            logger.info(f"   -> Loaded Train: {t_path.name}")
            
    # 2. åŠ è½½ Evaluation Set
    if e_path and e_path.exists():
        d = loadmat(str(e_path))
        # æ‰«æç»“æœæ˜¾ç¤º E æ–‡ä»¶é‡Œæ˜¯ x_test
        if 'x_test' in d:
            X_list.append(d['x_test'])
            y_list.append(d['y_test'])
            logger.info(f"   -> Loaded Eval:  {e_path.name}")
    
    if not X_list:
        raise ValueError("BCIC load failed: No data found in T or E files.")

    # 3. åˆå¹¶
    X = np.concatenate(X_list, axis=0)
    y = np.concatenate(y_list, axis=0).flatten()
    
    # 4. è£å‰ªé€šé“ (ä¿ç•™å‰22ä¸ª EEG)
    # æ‰«æç»“æœæ˜¾ç¤º shape æ˜¯ (288, 22, 562)ï¼Œå·²ç»æ˜¯ 22 é€šé“äº†ï¼Œä½†ä¿é™©èµ·è§
    if X.shape[1] > 22:
        X = X[:, :22, :]
        
    return X, y

def _load_standard(path, key_x='x_test', key_y='y_test'):
    """æ ‡å‡†åŠ è½½ (BCIcha / MAMEM)"""
    d = loadmat(str(path))
    X = d[key_x]
    y = d[key_y].flatten()
    return X, y

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  4. ç»Ÿä¸€å…¥å£
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_unified(dataset_name: str, subject_id: int, data_dir: str = 'data'):
    dataset_name = dataset_name.lower()
    meta = DATASET_META.get(dataset_name)
    
    if not meta:
        raise ValueError(f"Unknown dataset: {dataset_name}")

    # æœç´¢è·¯å¾„
    root = Path(data_dir)
    search_paths = [
        root,
        root / meta['folder'],
        root / "author_original", 
        root / "my_custom"
    ]

    X, y = None, None

    # â”€â”€â”€ åˆ†æ”¯ 1: BCIC (éœ€è¦æ‰¾ä¸¤ä¸ªæ–‡ä»¶) â”€â”€â”€
    if dataset_name == 'bcic':
        # æ„é€ æ–‡ä»¶å: BCIC_S01_T.mat å’Œ BCIC_S01_E.mat
        fname_t = f"BCIC_S{subject_id:02d}_T.mat"
        fname_e = f"BCIC_S{subject_id:02d}_E.mat"
        
        path_t = find_file(search_paths, fname_t)
        path_e = find_file(search_paths, fname_e)
        
        if not path_t and not path_e:
             # å°è¯• fallback: A01T.mat (åŸå§‹æ ¼å¼)
            fname_t_alt = f"A{subject_id:02d}T.mat"
            fname_e_alt = f"A{subject_id:02d}E.mat"
            path_t = find_file(search_paths, fname_t_alt)
            path_e = find_file(search_paths, fname_e_alt)

        if not path_t and not path_e:
            raise FileNotFoundError(f"Missing BCIC files for Subject {subject_id} (searched for {fname_t}/{fname_e})")
            
        X, y = _load_bcic_merged(path_t, path_e)

    # â”€â”€â”€ åˆ†æ”¯ 2: MAMEM â”€â”€â”€
    elif dataset_name == 'mamem':
        fname = f"U{subject_id:03d}.mat"
        path = find_file(search_paths, fname)
        if not path:
             raise FileNotFoundError(f"Missing MAMEM file: {fname}")
        logger.info(f"ğŸ“¥ Loading: {path.name}")
        X, y = _load_standard(path, 'x_test', 'y_test')

    # â”€â”€â”€ åˆ†æ”¯ 3: BCIcha â”€â”€â”€
    elif dataset_name == 'bcicha':
        fname = f"Data_S{subject_id:02d}_Sess.mat"
        path = find_file(search_paths, fname)
        if not path:
             raise FileNotFoundError(f"Missing BCIcha file: {fname}")
        logger.info(f"ğŸ“¥ Loading: {path.name}")
        X, y = _load_standard(path, 'x_test', 'y_test')

    # â”€â”€â”€ é€šç”¨é¢„å¤„ç† â”€â”€â”€
    
    # 1. è£å‰ªæ—¶é—´çª—
    target_T = meta['T']
    current_T = X.shape[2]
    
    if current_T > target_T:
        # å±…ä¸­è£å‰ª
        start = (current_T - target_T) // 2
        X = X[:, :, start:start+target_T]
    elif current_T < target_T:
        logger.warning(f"âš ï¸ Padding data: {current_T} -> {target_T}")
        pad_len = target_T - current_T
        X = np.pad(X, ((0,0), (0,0), (0, pad_len)))

    # 2. æ ‡å‡†åŒ–
    X = normalize(X)
    
    # 3. æ ‡ç­¾ä» 0 å¼€å§‹
    if y.min() == 1:
        y = y - 1
        
    # 4. ç±»å‹è½¬æ¢
    return jnp.array(X, dtype=jnp.float32), jnp.array(y, dtype=jnp.int32)