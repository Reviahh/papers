# src/run_final.py
"""
CMSAN æé€Ÿå¤ç°è„šæœ¬ (i5-12500H ä¼˜åŒ–ç‰ˆ)
ç›®æ ‡: å•è¿›ç¨‹+å¤šçº¿ç¨‹è®¡ç®—ï¼Œ1å°æ—¶å†…è·‘å®Œæ‰€æœ‰ Benchmarks
"""

import os
import sys
import time
import argparse
import logging
import numpy as np
from pathlib import Path
from scipy.io import loadmat
from sklearn.model_selection import KFold

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. æ€§èƒ½ç¯å¢ƒé…ç½® (å¿…é¡»åœ¨ import jax ä¹‹å‰ !)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ã€æ ¸å¿ƒæé€Ÿã€‘: å…è®¸ Eigen ä½¿ç”¨å¤šçº¿ç¨‹ (åˆ©ç”¨ä½ çš„ 12æ ¸ 16çº¿ç¨‹)
os.environ['XLA_FLAGS'] = '--xla_cpu_multi_thread_eigen=true' 

# å…³é—­å†…å­˜é¢„åˆ†é…ï¼Œé˜²æ­¢ Windows ä¸‹å ç”¨è¿‡é«˜
os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'
# å¼ºåˆ¶ä½¿ç”¨ CPU
os.environ['JAX_PLATFORMS'] = 'cpu'

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. JAX & åº“å¯¼å…¥
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(message)s',
    datefmt='%H:%M:%S',
    handlers=[
        logging.FileHandler("experiment_results.log", mode='w'), # ç»“æœå­˜æ–‡ä»¶
        logging.StreamHandler(sys.stdout)                        # åŒæ—¶æ‰“å°åˆ°å±å¹•
    ]
)
logger = logging.getLogger()

logger.info("æ­£åœ¨åˆå§‹åŒ– JAX ç¯å¢ƒ (åˆ©ç”¨å…¨æ ¸åŠ é€Ÿ)...")

import jax
import jax.numpy as jnp
from jax import random
import equinox as eqx
import optax

# å¯¼å…¥ä½ çš„æ ¸å¿ƒåº“ (ç¡®ä¿ src åœ¨ PYTHONPATH ä¸­ï¼Œæˆ–è€…æ­¤è„šæœ¬åœ¨ src ä¸‹è¿è¡Œ)
try:
    from cmsan import CMSAN, batch_predict
    from cmsan.train import compute_loss
except ImportError:
    logger.error("âŒ æ‰¾ä¸åˆ° cmsan åº“ã€‚è¯·ç¡®ä¿ä½ åœ¨ src ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬: python run_final.py")
    sys.exit(1)

logger.info(f"âœ… JAX è®¾å¤‡: {jax.devices()[0].device_kind} (æ ¸å¿ƒæ•°å·²é‡Šæ”¾)")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. å®éªŒé…ç½® (Configuration)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# æ•°æ®é›†å…ƒæ•°æ®
DATASET_META = {
    'bcic':   {'C': 22, 'T': 438, 'K': 4, 'D': 20, 'S': 3, 'subjects': range(1, 10)},
    'mamem':  {'C': 8,  'T': 125, 'K': 5, 'D': 15, 'S': 3, 'subjects': range(1, 12)},
    'bcicha': {'C': 56, 'T': 160, 'K': 2, 'D': 14, 'S': 3, 
               'subjects': [2,6,7,11,12,13,14,16,17,18,20,21,22,23,24,26]},
}

# è®­ç»ƒè¶…å‚æ•° (é’ˆå¯¹ 1 å°æ—¶å®Œèµ›è°ƒæ•´)
TRAIN_CONFIG = {
    'epochs': 30,       # è¶³å¤Ÿè§‚å¯Ÿæ”¶æ•›è¶‹åŠ¿
    'batch_size': 32,   
    'lr': 1e-3,
    'n_folds': 3        # 3æŠ˜äº¤å‰éªŒè¯ (å¹³è¡¡é€Ÿåº¦ä¸å¯ä¿¡åº¦)
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. æ•°æ®åŠ è½½æ¨¡å— (é€‚é…ä½ çš„ç›®å½•ç»“æ„)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_data_path(base_dir, mode, dataset_name):
    """æ ¹æ®æ¨¡å¼é€‰æ‹©æ•°æ®æ–‡ä»¶å¤¹"""
    root = Path(base_dir) / "data"
    if mode == 'author':
        target = root / "author_original"
        # å¦‚æœä½œè€…åŸæ–‡ä»¶å¤¹æ²¡åˆ†é‚£ä¹ˆç»†ï¼Œæ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹è¿™é‡Œ
        # è¿™é‡Œå‡è®¾ä½ æŠŠæ‰€æœ‰ .mat æŒ‰æ•°æ®é›†åˆ†æ–‡ä»¶å¤¹æ”¾è¿›äº† author_original
        # æˆ–è€…å…¼å®¹ä½ ç°åœ¨çš„ç»“æ„ï¼š
        return root # å›é€€åˆ° data/ æ ¹ç›®å½•æŸ¥æ‰¾
    else:
        return root / "my_custom"

def load_data(data_root, dataset, subject):
    """ç»Ÿä¸€æ•°æ®åŠ è½½å…¥å£"""
    path = Path(data_root)
    
    try:
        if dataset == 'bcic':
            # é€‚é… BCICIV_2a_mat æ–‡ä»¶å¤¹
            folder = path / "BCICIV_2a_mat"
            if not folder.exists(): folder = path # å°è¯•ç›´æ¥åœ¨ root æ‰¾
            
            t = loadmat(str(folder / f"BCIC_S{subject:02d}_T.mat"))
            e = loadmat(str(folder / f"BCIC_S{subject:02d}_E.mat"))
            
            # æ‹¼æ¥ Train å’Œ Test
            X = np.concatenate([t.get('x_train', t.get('x_test')), e['x_test']], axis=0)
            y = np.concatenate([t.get('y_train', t.get('y_test')).flatten(), e['y_test'].flatten()])
            
            # è£å‰ªæ—¶é—´çª— (é¿å…å†…å­˜çˆ†ç‚¸)
            T_target = DATASET_META['bcic']['T']
            T_start = (X.shape[2] - T_target) // 2
            X = X[:, :, T_start:T_start+T_target]
            
        elif dataset == 'mamem':
            folder = path / "MAMEM"
            d = loadmat(str(folder / f"U{subject:03d}.mat"))
            X, y = d['x_test'], d['y_test'].flatten()
            
        elif dataset == 'bcicha':
            folder = path / "BCIcha"
            d = loadmat(str(folder / f"Data_S{subject:02d}_Sess.mat"))
            X, y = d['x_test'], d['y_test'].flatten()
            
        return X.astype(np.float32), (y - y.min()).astype(np.int32)
    
    except FileNotFoundError:
        logger.error(f"âŒ æ•°æ®æ–‡ä»¶ä¸¢å¤±: {dataset} Subject {subject}")
        logger.error(f"   è¯·æ£€æŸ¥è·¯å¾„: {path}")
        sys.exit(1)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. è®­ç»ƒæ ¸å¿ƒ (ä¼˜åŒ–ç¼–è¯‘ç‰ˆ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def make_train_step(optimizer):
    """å·¥å‚æ¨¡å¼ï¼šç”Ÿæˆ JIT ç¼–è¯‘çš„è®­ç»ƒæ­¥"""
    @eqx.filter_jit
    def train_step(model, opt_state, x, y):
        loss, grads = eqx.filter_value_and_grad(compute_loss)(model, x, y)
        updates, opt_state = optimizer.update(grads, opt_state, eqx.filter(model, eqx.is_array))
        model = eqx.apply_updates(model, updates)
        return model, opt_state, loss
    return train_step

@eqx.filter_jit
def evaluate(model, X, y):
    preds = batch_predict(model, X)
    return jnp.mean(preds == y)

def run_subject_cv(data_root, dataset, subject, cfg):
    """å•ä¸ªè¢«è¯•çš„äº¤å‰éªŒè¯æµç¨‹"""
    X, y = load_data(data_root, dataset, subject)
    
    # K-Fold è®¾ç½®
    kf = KFold(n_splits=TRAIN_CONFIG['n_folds'], shuffle=True, random_state=42)
    accs = []

    # å‡†å¤‡ JAX éšæœº 
    # (æ³¨æ„ï¼šåœ¨å¾ªç¯å¤–ç”Ÿæˆ key é¿å…æ¯æ¬¡é‡æ–°åˆå§‹åŒ–)
    key = random.PRNGKey(subject * 999) 

    # å¾ªç¯ Folds
    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X)):
        # 1. æ•°æ®å‡†å¤‡ (Numpy -> JAX Array)
        X_tr, X_val = X[train_idx], X[val_idx]
        y_tr, y_val = y[train_idx], y[val_idx]
        
        # æ ‡å‡†åŒ– (z-score)
        mean = X_tr.mean(axis=(0, 2), keepdims=True)
        std  = X_tr.std(axis=(0, 2), keepdims=True) + 1e-8
        X_tr = jnp.array((X_tr - mean) / std)
        X_val = jnp.array((X_val - mean) / std)
        y_tr, y_val = jnp.array(y_tr), jnp.array(y_val)

        # 2. æ¨¡å‹åˆå§‹åŒ–
        key, m_key = random.split(key)
        model = CMSAN(m_key, C=cfg['C'], T=cfg['T'], D=cfg['D'], S=cfg['S'], K=cfg['K'])
        
        optimizer = optax.adamw(TRAIN_CONFIG['lr'])
        opt_state = optimizer.init(eqx.filter(model, eqx.is_array))
        train_step = make_train_step(optimizer)

        # 3. è®­ç»ƒå¾ªç¯ (æœ€è€—æ—¶éƒ¨åˆ†)
        n_samples = X_tr.shape[0]
        batch_size = TRAIN_CONFIG['batch_size']
        
        for epoch in range(TRAIN_CONFIG['epochs']):
            # Shuffle
            key, p_key = random.split(key)
            perm = random.permutation(p_key, n_samples)
            X_shuf, y_shuf = X_tr[perm], y_tr[perm]
            
            # Batch Loop
            for i in range(0, n_samples, batch_size):
                end = min(i + batch_size, n_samples)
                model, opt_state, _ = train_step(model, opt_state, X_shuf[i:end], y_shuf[i:end])
        
        # 4. è¯„ä¼°
        acc = float(evaluate(model, X_val, y_val))
        accs.append(acc)
    
    return np.mean(accs)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. ä¸»æ§é€»è¾‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(description="CMSAN å¿«é€Ÿå¤ç°è„šæœ¬")
    parser.add_argument('--dataset', default='all', choices=['bcic', 'mamem', 'bcicha', 'all'])
    parser.add_argument('--mode', default='author', choices=['author', 'my'], help="åŒºåˆ†æ•°æ®æ¥æº")
    parser.add_argument('--data_dir', default='data', help="æ•°æ®æ ¹ç›®å½•") # é»˜è®¤æŒ‡å‘ ./data
    args = parser.parse_args()

    # ç¡®å®šè¦è·‘çš„ä»»åŠ¡
    target_datasets = DATASET_META.keys() if args.dataset == 'all' else [args.dataset]
    
    # æ‰“å°æ¨ªå¹…
    logger.info("="*60)
    logger.info(f"ğŸš€ CMSAN æé€Ÿå®éªŒ | æ¨¡å¼: {args.mode.upper()}")
    logger.info(f"âš™ï¸  è®¾ç½®: Epochs={TRAIN_CONFIG['epochs']} | Folds={TRAIN_CONFIG['n_folds']}")
    logger.info("="*60)

    total_start = time.time()
    final_report = {}

    for ds_name in target_datasets:
        cfg = DATASET_META[ds_name]
        subs = cfg['subjects']
        
        logger.info(f"\nğŸ“Š å¼€å§‹æ•°æ®é›†: {ds_name.upper()} (N={len(subs)})")
        logger.info("-" * 40)
        
        ds_accs = []
        ds_start = time.time()
        
        # é€ä¸ªè·‘ Subject (å•è¿›ç¨‹ï¼Œä½†å†…éƒ¨ JAX æ»¡è½½å¤šçº¿ç¨‹)
        for i, sub in enumerate(subs):
            t0 = time.time()
            
            # æ ¸å¿ƒè¿è¡Œ
            acc = run_subject_cv(args.data_dir, ds_name, sub, cfg)
            ds_accs.append(acc)
            
            # è¿›åº¦æ¡ä¼°ç®—
            elapsed = time.time() - ds_start
            avg_time = elapsed / (i + 1)
            remain = avg_time * (len(subs) - i - 1)
            
            logger.info(f"  Subject {sub:02d}: {acc*100:05.2f}% | è€—æ—¶ {time.time()-t0:3.0f}s | å‰©ä½™çº¦ {remain/60:.1f}m")

        # æ•°æ®é›†æ±‡æ€»
        mean, std = np.mean(ds_accs)*100, np.std(ds_accs)*100
        final_report[ds_name] = f"{mean:.2f} Â± {std:.2f}%"
        logger.info(f"ğŸ¯ {ds_name.upper()} å®Œæˆ: {mean:.2f}% (è€—æ—¶ {(time.time()-ds_start)/60:.1f}m)")

    # æœ€ç»ˆå¤§æ±‡æ€»
    logger.info("\n" + "="*60)
    logger.info("ğŸ“‹ æœ€ç»ˆå®éªŒæŠ¥å‘Š")
    logger.info("="*60)
    for k, v in final_report.items():
        logger.info(f"  {k.upper():<10} : {v}")
    logger.info(f"\nâ±ï¸  æ€»è€—æ—¶: {(time.time()-total_start)/60:.1f} åˆ†é’Ÿ")

if __name__ == '__main__':
    main()